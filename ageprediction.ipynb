{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e828f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T19:03:17.363564Z",
     "iopub.status.busy": "2024-04-16T19:03:17.363285Z",
     "iopub.status.idle": "2024-04-16T19:57:09.715669Z",
     "shell.execute_reply": "2024-04-16T19:57:09.714606Z"
    },
    "papermill": {
     "duration": 3232.357987,
     "end_time": "2024-04-16T19:57:09.717684",
     "exception": false,
     "start_time": "2024-04-16T19:03:17.359697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 163MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n",
      "Epoch 1/25, Train Loss: 18.6430, Val MAE: 14.7736\n",
      "Epoch 2/25, Train Loss: 14.2433, Val MAE: 13.3796\n",
      "Epoch 3/25, Train Loss: 13.1826, Val MAE: 12.6083\n",
      "Epoch 4/25, Train Loss: 12.3185, Val MAE: 11.5019\n",
      "Epoch 5/25, Train Loss: 11.6804, Val MAE: 11.1777\n",
      "Epoch 6/25, Train Loss: 11.4136, Val MAE: 10.8381\n",
      "Epoch 7/25, Train Loss: 11.1687, Val MAE: 11.1522\n",
      "Epoch 8/25, Train Loss: 11.1114, Val MAE: 10.5965\n",
      "Epoch 9/25, Train Loss: 10.8922, Val MAE: 10.4471\n",
      "Epoch 10/25, Train Loss: 10.7854, Val MAE: 10.3827\n",
      "Epoch 11/25, Train Loss: 10.5876, Val MAE: 10.4239\n",
      "Epoch 12/25, Train Loss: 10.5749, Val MAE: 10.3782\n",
      "Epoch 13/25, Train Loss: 10.4411, Val MAE: 10.0837\n",
      "Epoch 14/25, Train Loss: 10.3560, Val MAE: 10.1082\n",
      "Epoch 15/25, Train Loss: 10.3169, Val MAE: 10.0059\n",
      "Epoch 16/25, Train Loss: 10.3020, Val MAE: 10.0258\n",
      "Epoch 17/25, Train Loss: 10.2608, Val MAE: 9.8412\n",
      "Epoch 18/25, Train Loss: 10.1521, Val MAE: 10.0290\n",
      "Epoch 19/25, Train Loss: 10.1237, Val MAE: 10.0921\n",
      "Epoch 20/25, Train Loss: 10.2136, Val MAE: 9.7452\n",
      "Epoch 21/25, Train Loss: 10.0056, Val MAE: 9.7684\n",
      "Epoch 22/25, Train Loss: 9.9813, Val MAE: 9.7328\n",
      "Epoch 23/25, Train Loss: 10.0099, Val MAE: 9.6986\n",
      "Epoch 24/25, Train Loss: 9.8464, Val MAE: 9.6125\n",
      "Epoch 25/25, Train Loss: 9.9075, Val MAE: 9.5294\n",
      "Finished Training. Best Validation MAE: 9.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:18<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 11.6730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomRotation\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Augmentation\n",
    "class AgeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, annot_path, train=True):\n",
    "        super(AgeDataset, self).__init__()\n",
    "\n",
    "        self.annot_path = annot_path\n",
    "        self.data_path = data_path\n",
    "        self.train = train\n",
    "\n",
    "        self.ann = pd.read_csv(annot_path)\n",
    "        self.files = self.ann['file_id']\n",
    "        if train:\n",
    "            self.ages = self.ann['age']\n",
    "        \n",
    "        self.transform = self._transform(224)\n",
    "\n",
    "    @staticmethod    \n",
    "    def _convert_image_to_rgb(image):\n",
    "        return image.convert(\"RGB\")\n",
    "\n",
    "    def _transform(self, n_px):\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        return Compose([\n",
    "            Resize(n_px),\n",
    "            RandomHorizontalFlip(),  \n",
    "            RandomRotation(10),     \n",
    "            self._convert_image_to_rgb,\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std),\n",
    "        ])\n",
    "\n",
    "    def read_img(self, file_name):\n",
    "        im_path = join(self.data_path,file_name)   \n",
    "        img = Image.open(im_path)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        img = self.read_img(file_name)\n",
    "        if self.train:\n",
    "            age = self.ages[index]\n",
    "            return img, age\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "# Paths\n",
    "train_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train'\n",
    "train_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv'\n",
    "test_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/test'\n",
    "test_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/submission.csv'\n",
    "\n",
    "# Datasets\n",
    "train_dataset = AgeDataset(train_path, train_ann, train=True)\n",
    "test_dataset = AgeDataset(test_path, test_ann, train=False)\n",
    "\n",
    "# Data Loaders\n",
    "train_indices, val_indices = train_test_split(range(len(train_dataset)), test_size=0.1, random_state=42, shuffle=True)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model with Transfer Learning and Fine-tuning\n",
    "class AgePredictor(nn.Module):\n",
    "    def __init__(self, model_name=\"resnet50\", pretrained=True):\n",
    "        super(AgePredictor, self).__init__()\n",
    "        if model_name == \"resnet34\":\n",
    "            self.model = torchvision.models.resnet34(pretrained=pretrained)\n",
    "        elif model_name == \"resnet50\":\n",
    "#             self.model = torchvision.models.resnet50(pretrained=pretrained)\n",
    "            self.model = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model name. Choose 'resnet18' or 'resnet34'\")\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        # Wrap the model with DataParallel\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = AgePredictor().to(device)\n",
    "\n",
    "def test_loss(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.flatten(), labels.float())\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    return total_loss / total_samples\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, epochs=25, patience=5):\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
    "    best_mae = float('inf')\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.flatten(), labels.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        val_mae = test_loss(model, val_loader, criterion)\n",
    "        \n",
    "        scheduler.step(val_mae)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader):.4f}, Val MAE: {val_mae:.4f}')\n",
    "        \n",
    "        if val_mae < best_mae:\n",
    "            best_mae = val_mae\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, 'best_model.pth')\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        \n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f'Early stopping after {patience} epochs of no improvement.')\n",
    "            break\n",
    "            \n",
    "    print(f'Finished Training. Best Validation MAE: {best_mae:.4f}')\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.L1Loss()(outputs.flatten(), labels.float())\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    return total_loss / total_samples\n",
    "\n",
    "def predict(loader, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader):\n",
    "            inputs = inputs.to(device)\n",
    "            pred = model(inputs)\n",
    "            predictions.extend(pred.flatten().cpu().detach().numpy().tolist())\n",
    "    return predictions\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, criterion, epochs=25, patience=5)\n",
    "\n",
    "# Load the best model\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = predict(test_loader, model)\n",
    "\n",
    "# Calculate MAE on test set\n",
    "test_labels = pd.read_csv(test_ann)['age'].values\n",
    "test_mae = mean_absolute_error(test_labels, preds)\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submit = pd.read_csv(test_ann)\n",
    "submit['age'] = preds\n",
    "submit.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1877e36",
   "metadata": {
    "papermill": {
     "duration": 0.007136,
     "end_time": "2024-04-16T19:57:09.732493",
     "exception": false,
     "start_time": "2024-04-16T19:57:09.725357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8130765,
     "sourceId": 74586,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3237.682311,
   "end_time": "2024-04-16T19:57:12.052106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T19:03:14.369795",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
